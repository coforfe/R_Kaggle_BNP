################################################################################
## https://www.kaggle.com/c/bnp-paribas-cardif-claims-management
## Rossmann Store Sales
## Santiago Mota
## santiago_mota@yahoo.es

# Can you accelerate BNP Paribas Cardif's claims management process?

# As a global specialist in personal insurance, BNP Paribas Cardif serves 90 
# million clients in 36 countries across Europe, Asia and Latin America.

# In a world shaped by the emergence of new uses and lifestyles, everything is 
# going faster and faster. When facing unexpected events, customers expect their 
# insurer to support them as soon as possible. However, claims management may 
# require different levels of check before a claim can be approved and a payment 
# can be made. With the new practices and behaviors generated by the digital 
# economy, this process needs adaptation thanks to data science to meet the new 
# needs and expectations of customers.

# In this challenge, BNP Paribas Cardif is providing an anonymized database with 
# two categories of claims:

# - claims for which approval could be accelerated leading to faster payments
# - claims for which additional information is required before approval

# Kagglers are challenged to predict the category of a claim based on features 
# available early in the process, helping BNP Paribas Cardif accelerate its 
# claims process and therefore provide a better service to its customers.

# Started: 8:48 pm, Wednesday 3 February 2016 UTC
# Ends: 11:59 pm, Monday 18 April 2016 UTC (75 total days)
# Points: this competition awards standard ranking points
# Tiers: this competition counts towards tiers

# Data Files
# File Name 	      Available Formats
# sample_submission.csv .zip (162.38 kb)
# test.csv 	            .zip (49.37 mb)
# train.csv 	      .zip (49.42 mb)
# 
# You are provided with an anonymized dataset containing both categorical and 
# numeric variables available when the claims were received by BNP Paribas 
# Cardif. All string type variables are categorical. There are no ordinal 
# variables.

# The "target" column in the train set is the variable to predict. It is equal 
# to 1 for claims suitable for an accelerated approval.
 
# The task is to predict a probability ("PredictedProb") for each claim in the 
# test set.

# File descriptions
 
# train.csv - the training set including the target
# test.csv - the test set without the target
# sample_submission.csv - a sample submission file in the correct format


################################################################################

# Some initial work
Sys.setenv(LANGUAGE="en")
set.seed(1967)

# Info session
sessionInfo()

# Show elements working directory
ls()

# Gets you the current working directory
getwd()                    

# Lists all the files present in the current working directory
dir()

# Updates all packages
update.packages() 

library(ggplot2) 
library(readr) 
library(xgboost)

# Load data
train  <- read.table("./data/train.csv", header=T, sep=",")
test   <- read.table("./data/test.csv", header=T, sep=",") 

# Data names and summary
names(train)
str(train)
summary(train)
names(test)
str(test)
summary(test)

library(Hmisc)
describe(train)
describe(test)

# Integer (6)
variables_integer <- names(Filter(function(x) x=="integer", sapply(train, class)))
variables_integer

# numeric (108)
variables_numeric <- names(Filter(function(x) x=="numeric", sapply(train, class)))
variables_numeric

# factor (19)
variables_factor <- names(Filter(function(x) x=="factor", sapply(train, class)))
variables_factor

# Table variables
for (i in 1:dim(train)[2]) {
      print(names(train)[i])
      print(table(train[, i], useNA='ifany'))
      # plot(train[, i], main = i)
}

# Plot variables. Time consumming
for (i in 1:dim(train)[2]) {
      plot(train[, i], main=names(train)[i])
}

for (i in variables_numeric) {
      hist(train[, i], main=i)
}

ggplot(train, aes(variables_numeric[3], colour = target)) +
      geom_histogram(binwidth = 1)

ggplot(train, aes(variables_numeric[3], colour = target)) +
      geom_freqpoly(binwidth = 1)

# ggplot(diamonds, aes(price, fill = cut)) + geom_histogram(binwidth = 500)
# ggplot(diamonds, aes(price, colour = cut)) + geom_freqpoly(binwidth = 500)

library(corrplot)
corrplot(cor(train[, variables_integer]), method="number", 
         order="hclust", type='lower', diag=F, addCoefasPercent=T)

# corrplot(cor(train[, variables_numeric]), method="number", 
# order="hclust", type='lower', diag=F, addCoefasPercent=T)

M <- train[, -1]
corrplot(cor(M), method="number", order="hclust", type='lower', 
         diag=F, addCoefasPercent=T)

# variables information value
library(woe)
target <- train$target
train$target <- as.factor(train$target)
information_value <- iv.mult(train, "target", TRUE)     # Time consumming
save(information_value, file="information_value.RData")
iv.plot.summary(iv.mult(train, "target", TRUE))         # Time consumming
train$target <- target

# iv.num          – calculate WoE/IV for numeric variables
# iv.str          – calculate WoE/IV for character/factor variables
# iv.mult         – calculate WoE/IV, summary IV for one or more variables
# iv.plot.summary – plot IV summary
# iv.plot.woe     – plot WoE patterns for one or more variables
# iv.replace.woe  – recode original variables to WoE (adds new columns)

# load("information_value.RData")
head(information_value, 14)
variables_top_14 <- information_value$Variable[1:14]


# Separate target
train  <- train[, -2]
target <- train[, 'target']

# NA Values
train[is.na(train)] <- -1
test[is.na(test)]   <- -1

# Find factor variables and translate to numeric
f <- c()
for(i in 1:ncol(train)) {
      if (is.factor(train[, i])) f <- c(f, i)
}

f.t <- c()
for(i in 1:ncol(test)) {
      if (is.factor(test[, i])) f.t <- c(f.t, i)
}

# Make a total dataset
total <- rbind(train, test)
for (i in f) {
      total[, i] <- as.numeric(total[, i]) 
}
train <- total[1:nrow(train), ]
test  <- total[(nrow(train)+1):nrow(total), ]


